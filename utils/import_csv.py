# A real quick-and-dirty hack right now for importing csv files
import sys
import os.path
import csv
from requests import HTTPError
from deriva.core import DerivaServer, get_credential
from deriva.core.ermrest_model import Table, Column, Key, builtin_types

if len(sys.argv) < 4:
    print('usage: %(prog)s hostname { catalog | - } files...' % {'prog': sys.argv[0]})
    exit(1)

# General settings
schema_name = 'public'  # name of the schema to load the table into
use_syscols = True  # create table with system columns
use_delimiter = None  # set delimited; e.g., set to '\t' for tab delimited
drop_table = True  # set to true, to drop existing table of same name and redefine

# Formatting settings
# This script reads a csv file with additional "header" sub-headings, in this order:
#   - standard header (expected)
#   - display name
#   - comments
#   - types (use ermrest typenames)
#   - annotations (currently single tag w/out body only)
#   - value mappings (of the form "#=term\t...")
has_display_name = True
has_comments = True
has_types = True
has_annotations = True
has_value_map = True

# Arguments
hostname = sys.argv[1]
catalog_num = sys.argv[2] if sys.argv[2] != "-" else None  # if '-' a new catalog will be created
csv_files = sys.argv[3:]

# Create/connect catalog and get various interfaces
credential = get_credential(hostname)
server = DerivaServer('https', hostname, credential)
catalog = server.connect_ermrest(catalog_num) if catalog_num else server.create_ermrest_catalog()
model = catalog.getCatalogModel()
public = model.schemas[schema_name]
config = catalog.getCatalogConfig()

# ACLs to be defined on catalog and table
acls = {
    "select": ['*'],
    "enumerate": ['*']
}

if not catalog_num:
    # Only when creating a new catalog do we update its ACLs.
    config.acls.update(acls)
    catalog.applyCatalogConfig(config)


def valid_value(val, vtype, vmap=None):
    """ This is a very quick and dirty validator for input values.
    val: the value
    vtype: the value type as an ermrest type
    vmap: the value map dictionary
    """
    if isinstance(val, int):
        # accept all integers
        return val
    elif vtype == builtin_types.timestamp or vtype == builtin_types.timestamptz:
        # make sure timestamps are sent as empty "" strings or invalid values 
        if len(val) and val != "not reported" and val != "unreported":
            return val
        else:
            return None
    elif vmap:
        # if there is a data dictionary value mapping, use it
        return vmap.get(val, None)
    elif len(val):
        # any non-empty string accepted
        return val.strip()
    else:
        return None


for fname in csv_files:
    print('Importing {fname}...'.format(fname=fname))
    tname = os.path.splitext(os.path.basename(fname))[0]
    visible_columns = []

    if tname in public.tables:
        print("Found existing table '{tname}' in catalog".format(tname=tname))
        if drop_table:
            table = public.tables[tname]
            table.delete(catalog, public)
            print("Dropped table from catalog")
        else:
            print("Skipping '{tname}'. Set 'drop_table' to True to drop, redefine and import".format(tname=tname))
            continue

    if not use_syscols:
        pk = 'key'
        col_defs = [Column.define(pk, builtin_types.int8, comment="Row key (generated by client tool on import)")]
        key_defs = [Key.define([pk])]
        types = {pk: builtin_types.int8}
    else:
        col_defs = []
        key_defs = []
        types = {}
        visible_columns.append('RID')

    with open(fname) as csvfile:
        reader = csv.DictReader(csvfile, delimiter=use_delimiter) if use_delimiter else csv.DictReader(csvfile)
        display_names = next(reader) if has_display_name else {}
        comments = next(reader) if has_comments else {}
        typenames = next(reader) if has_types else {}
        annotations = next(reader) if has_annotations else {}
        dictionary = next(reader) if has_value_map else {}

        for cname in reader.fieldnames:
            visible_columns.append(cname)
            comment = comments.get(cname)
            ctype = builtin_types[typenames.get(cname)] if typenames.get(cname) else builtin_types.text
            types[cname] = ctype
            if dictionary.get(cname):
                dictionary[cname] = {kv.split('=')[0]: kv.split('=')[1] for kv in dictionary[cname].split('\n')}
            annotation = {annotations[cname]: None} if annotations.get(cname) else {}
            if display_names.get(cname):
                annotation["tag:misd.isi.edu,2015:display"] = {"markdown_name": display_names.get(cname)}
            col_defs.append(Column.define(cname, ctype, comment=comment, annotations=annotation))

        tab_def = Table.define(tname,
                               column_defs=col_defs,
                               key_defs=key_defs,
                               acls=acls,
                               annotations={
                                   "tag:isrd.isi.edu,2016:visible-columns": {"*": visible_columns}
                               },
                               provide_system=use_syscols)

        print('Creating table {tname}...'.format(tname=tname))
        try:
            public.create_table(catalog, tab_def)
        except HTTPError as e:
            print(e)
            print(e.response.text)
            exit(1)

        # Now to import data...
        pb = catalog.getPathBuilder()
        table = pb.public.tables[tname]

        print('Importing data into {tname}'.format(tname=tname))
        print(table.uri)

        done = False
        while not done:
            i, max, done = 0, 1000, True
            entities = []
            # read from file the next batch of entities
            for row in reader:
                entity = dict(row)
                if not use_syscols:
                    entity[pk] = reader.line_num
                entity = {k: valid_value(v, types[k], dictionary.get(k)) for k,v in entity.items()}
                entities.append(entity)
                i += 1
                if i >= max:
                    done = False
                    break
            # insert the entities into the ermrest table
            print('Importing {num} entities into {tname}'.format(num=i, tname=tname))
            try:
                table.insert(entities, add_system_defaults=False)
            except HTTPError as e:
                print(e)
                print(e.response.text)
                exit(1)

        print('Done importing into {tname}'.format(tname=tname))

