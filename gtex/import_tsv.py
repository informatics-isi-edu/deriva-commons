# A real quick-and-dirty hack right now for importing csv files
import sys
import os.path
import csv
from requests import HTTPError
from deriva.core import DerivaServer, get_credential
from deriva.core.ermrest_model import Table, Column, Key, builtin_types

if len(sys.argv) < 3:
    print('usage: {prog} hostname files...'.format(prog=sys.argv[0]))
    exit(1)

# Settings
catalog_num = None  # set to a catalog number or None to create a new one
schema_name = 'public'  # name of the schema to load the table into
use_syscols = False  # create table with system columns
has_comments = True  # set to true if second row of file is a comment for the header
has_dict = True  # set to true if third row indicates data dict of the form "#=term\t..."
has_types = True  # set to true if fourth row indicates the column type (float only supported)
has_annotations = True  # set to true if fifth row indicates annotations (currently single tag w/out body only)
use_delimiter = None  # set delimited; e.g., set to '\t' for tab delimited

# Args
hostname = sys.argv[1]
csv_files = sys.argv[2:]

# Create/connect catalog and get various interfaces
credential = get_credential(hostname)
server = DerivaServer('https', hostname, credential)
catalog = server.connect_ermrest(catalog_num) if catalog_num else server.create_ermrest_catalog()
model = catalog.getCatalogModel()
public = model.schemas[schema_name]
config = catalog.getCatalogConfig()

# Update catalog config
acls = {
    "select": ['*'],
    "enumerate": ['*']
}
config.acls.update(acls)
catalog.applyCatalogConfig(config)


def valid_value(val, vtype, vmap=None):
    """ This is a very quick and dirty validator for input values.
    val: the value
    vtype: the value type as an ermrest type
    vmap: the value map dictionary
    """
    if isinstance(val, int):
        # accept all integers
        return val
    elif vtype == builtin_types.timestamp or vtype == builtin_types.timestamptz:
        # make sure timestamps are sent as empty "" strings or invalid values 
        if len(val) and val != "not reported" and val != "unreported":
            return val
        else:
            return None
    elif vmap:
        # if there is a data dictionary value mapping, use it
        return vmap.get(val, None)
    elif len(val):
        # any non-empty string accepted
        return val.strip()
    else:
        return None


for fname in csv_files:
    print('Importing {fname}...'.format(fname=fname))
    tname = os.path.splitext(os.path.basename(fname))[0]

    if not use_syscols:
        pk = 'key'
        col_defs = [Column.define(pk, builtin_types.int8, comment="Row key (generated by client on import)")]
        key_defs = [Key.define([pk])]
        types = {pk: builtin_types.int8}
    else:
        col_defs = []
        key_defs = []
        types = {}

    with open(fname) as csvfile:
        reader = csv.DictReader(csvfile, delimiter=use_delimiter) if use_delimiter else csv.DictReader(csvfile)
        comments = next(reader) if has_comments else {}
        dictionary = next(reader) if has_dict else {}
        typenames = next(reader) if has_types else {}
        annotations = next(reader) if has_annotations else {}

        for cname in reader.fieldnames:
            comment = comments.get(cname)
            ctype = builtin_types[typenames.get(cname)] if typenames.get(cname) else builtin_types.text
            types[cname] = ctype
            if dictionary.get(cname):
                dictionary[cname] = {kv.split('=')[0]: kv.split('=')[1] for kv in dictionary[cname].split('\n')}
            annotation = {annotations[cname]: None} if annotations.get(cname) else {}
            col_defs.append(Column.define(cname, ctype, comment=comment, annotations=annotation))
        tab_def = Table.define(tname, column_defs=col_defs, key_defs=key_defs, acls=acls, provide_system=use_syscols)

        print('Creating table {tname}...'.format(tname=tname))
        try:
            public.create_table(catalog, tab_def)
        except HTTPError as e:
            print(e)
            print(e.response.text)
            exit(1)

        # Now to import data...
        pb = catalog.getPathBuilder()
        table = pb.public.tables[tname]

        print('Importing data into {tname}'.format(tname=tname))
        print(table.uri)

        done = False
        while not done:
            i, max, done = 0, 1000, True
            entities = []
            # read from file the next batch of entities
            for row in reader:
                entity = dict(row)
                if not use_syscols:
                    entity[pk] = reader.line_num
                entity = {k: valid_value(v, types[k], dictionary.get(k)) for k,v in entity.items()}
                entities.append(entity)
                i += 1
                if i >= max:
                    done = False
                    break
            # insert the entities into the ermrest table
            print('Importing {num} entities into {tname}'.format(num=i, tname=tname))
            try:
                table.insert(entities, add_system_defaults=False)
            except HTTPError as e:
                print(e)
                print(e.response.text)
                exit(1)

        print('Done importing into {tname}'.format(tname=tname))

